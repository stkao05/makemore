{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "34953c51-113f-4638-a085-78ec2bce7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "abe6ab3c-0b78-471e-858a-dcfcd913b79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_': 0,\n",
       " '0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10,\n",
       " '+': 11,\n",
       " '=': 12,\n",
       " ';': 13}"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_char = \";\"\n",
    "pad_char = \"_\"\n",
    "chars = list(\"_0123456789+=;\")\n",
    "vocab_size = len(chars)\n",
    "ctoi = {c:i for i, c in enumerate(chars)}\n",
    "itoc = {i:c for i, c in enumerate(chars)}\n",
    "\n",
    "eq_token = ctoi[\"=\"]\n",
    "stop_token = ctoi[\";\"]\n",
    "\n",
    "# return list of integer\n",
    "def encode(string):\n",
    "    return [ctoi[c] for c in string] \n",
    "\n",
    "def decode(tokens):\n",
    "    if isinstance(tokens, torch.Tensor):\n",
    "        return \"\".join([itoc[t.item()] for t in tokens])\n",
    "    else:\n",
    "        return \"\".join([itoc[t] for t in tokens])\n",
    "\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "c915bbcd-1201-4a31-bb94-7bfbc5a4d8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'39+30=96;'"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_eq():\n",
    "    a = torch.randint(0, 100, (1,))\n",
    "    b = torch.randint(0, 100, (1,))\n",
    "    c = a + b\n",
    "    cs = f\"{c.item()}\"[::-1]\n",
    "    \n",
    "    return f\"{a.item()}+{b.item()}={cs};\"\n",
    "\n",
    "\n",
    "generate_eq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "eda891ba-e2a4-4d7b-bf75-a0ea895e7fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, 0, 0]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad(ints, length):\n",
    "    assert length >= len(ints)\n",
    "    pn = length - len(ints)\n",
    "    return ints + [0]*pn\n",
    "        \n",
    "pad([1,2], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "ed4983d6-75e2-45e0-bdcb-8f2afbd2df62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5,  5, 11,  9,  8, 12,  2,  4,  2, 13,  0,  0],\n",
       "         [ 4, 10, 11, 10,  8, 12,  7,  4,  2, 13,  0,  0]]),\n",
       " tensor([[ 0,  0,  0,  0,  0,  0,  2,  4,  2, 13,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  7,  4,  2, 13,  0,  0]]))"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 12\n",
    "padding = 0\n",
    "\n",
    "# (B, L)\n",
    "def random_batch(batch_size):\n",
    "    eq_str = [generate_eq() for _ in range(batch_size)]\n",
    "    data = [pad(encode(s), max_len) for s in eq_str]\n",
    "    target = []\n",
    "    \n",
    "    for x in data:\n",
    "        y = list(x)\n",
    "        i = x.index(eq_token)\n",
    "        y[0:i+1] = [0]*(i+1)\n",
    "        target.append(y)\n",
    "        \n",
    "    return torch.tensor(data), torch.tensor(target)\n",
    "\n",
    "\n",
    "x, y = random_batch(2)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "79b38d89-27b5-48ce-948d-51a5e33cf2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27534"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = 64\n",
    "hidden_size = 128\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__();\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        y = self.emb(x)\n",
    "        y, h = self.rnn(y, hidden)\n",
    "        y = self.linear(y)\n",
    "        return y, h\n",
    "\n",
    "    \n",
    "model = Model()\n",
    "optim = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "sum([p.numel() for p in model.parameters()])\n",
    "\n",
    "# x, y = random_batch(1) # (N, L)\n",
    "# logits = model(x) # (N, L, vocab)\n",
    "\n",
    "# y = y[:,1:].view(-1)\n",
    "# logits = logits[:,1:,:].view(-1, vocab_size)\n",
    "# loss = F.cross_entropy(logits, y)\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "80b72bc5-6728-4c92-8e48-dd0a5ca9129b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6390573978424072"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.tensor(1/vocab_size).log().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "ab8dd2f8-5eff-4079-8d4b-46ce3da9c96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "a[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "51058ffa-d845-4379-bbc0-585ad4d1de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005985383759252727\n",
      "0.0019992964807897806\n",
      "0.001008582883514464\n",
      "0.0011705962242558599\n",
      "0.0008264639182016253\n",
      "0.000811861187685281\n",
      "0.0008374485187232494\n",
      "0.00032646741601638496\n",
      "0.0019043784122914076\n",
      "0.0009828548645600677\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for i in range(10000):\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    x, y = random_batch(32) # (N, L)\n",
    "    logits, _ = model(x)      # (N, L, vocab)\n",
    "    \n",
    "    # N, L = y\n",
    "    y = y[:,1:].reshape(-1)\n",
    "    logits = logits[:,:-1,:].reshape(-1, vocab_size)\n",
    "    \n",
    "    loss = F.cross_entropy(logits, y, ignore_index=0)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "7a2d9a39-746f-4201-832a-2ea0e9c3e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prob():\n",
    "    a = torch.randint(0, 100, (1,)).item()\n",
    "    b = torch.randint(0, 100, (1,)).item()\n",
    "    c = a + b\n",
    "    cs = f\"{c}\"[::-1]\n",
    "    return f\"{a}+{b}=\", c, cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "b35dd99a-548c-4377-8faa-b5daa5230afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('47+0=', 47, '74')"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "0d8fd96f-8316-4ffa-b4fb-5b937479fcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8+8= 16 61\n",
      "61\n",
      "\n",
      "\n",
      "56+35= 91 19\n",
      "19\n",
      "\n",
      "\n",
      "25+28= 53 35\n",
      "35\n",
      "\n",
      "\n",
      "49+19= 68 86\n",
      "86\n",
      "\n",
      "\n",
      "74+10= 84 48\n",
      "48\n",
      "\n",
      "\n",
      "52+36= 88 88\n",
      "88\n",
      "\n",
      "\n",
      "85+97= 182 281\n",
      "281\n",
      "\n",
      "\n",
      "79+26= 105 501\n",
      "501\n",
      "\n",
      "\n",
      "49+30= 79 97\n",
      "97\n",
      "\n",
      "\n",
      "35+75= 110 011\n",
      "011\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for _ in range(10):\n",
    "    prob, solu, rsolu = generate_prob()\n",
    "    print(prob, solu, rsolu)\n",
    "    \n",
    "    x = torch.tensor(encode(prob)).view(1, -1)\n",
    "    tokens = []\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(10):\n",
    "        logits, hidden = model(x, hidden)\n",
    "        last = logits[0,-1]\n",
    "        prob = F.softmax(last, dim=0)\n",
    "        ix = torch.multinomial(prob, 1)\n",
    "        if ix == stop_token:\n",
    "            break\n",
    "        tokens.append(ix)\n",
    "        x = ix.view(1, 1)\n",
    "\n",
    "    print(\"\".join([itoc[t.item()] for t in tokens]))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
