{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1f08f0-08f6-4d09-a495-9f6104dfdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plot\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466d2563-6357-4f8d-ae55-f45fbba4f704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['emma', 'olivia', 'ava', 'isabella', 'sophia'], 32033)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"names.txt\", \"r\") as f:\n",
    "    names = [_.strip() for _ in f.readlines()]\n",
    "\n",
    "names[0:5], len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d24d37e-fe18-4bc5-8429-509f8967b26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'v',\n",
       " 'f',\n",
       " 'b',\n",
       " 'x',\n",
       " 'i',\n",
       " 'g',\n",
       " 'r',\n",
       " 't',\n",
       " 'y',\n",
       " 'z',\n",
       " 'q',\n",
       " 'a',\n",
       " 'p',\n",
       " 'c',\n",
       " 'm',\n",
       " 's',\n",
       " 'e',\n",
       " 'n',\n",
       " 'j',\n",
       " 'w',\n",
       " 'l',\n",
       " 'u',\n",
       " 'h',\n",
       " 'o',\n",
       " 'k',\n",
       " 'd']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(set(\"\".join(names)))\n",
    "chars.insert(0, \".\")\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ecb7279-15ec-4185-84ad-f44d0d231019",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctoi = { c:i for i, c in enumerate(chars)}\n",
    "itoc = { i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a844b3bf-c723-4b44-b011-b54e76371c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1418770a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int) # N is count vector\n",
    "\n",
    "for x in names:\n",
    "    x = \".\" + x + \".\"\n",
    "    for c1, c2 in zip(x, x[1:]):\n",
    "        c1i = ctoi[c1]\n",
    "        c2i = ctoi[c2]\n",
    "        N[c1i, c2i] += 1\n",
    "        \n",
    "plot.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "841f85a6-1f7d-439a-bd4e-47324d3e44ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = N / N.sum(dim=1, keepdims=True)\n",
    "P[5,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b672955-3cbb-4160-a900-298ec96ed0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = []\n",
    "for x in names:\n",
    "    x = \".\" + x + \".\"\n",
    "    for c1, c2 in zip(x, x[1:]):\n",
    "        bigrams.append((c1, c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "243087a3-4e53-4a32-91eb-e4a5d47c8b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.454014497322693"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp = 0;\n",
    "for c1, c2 in bigrams:\n",
    "    c1 = ctoi[c1]\n",
    "    c2 = ctoi[c2]\n",
    "    logp += P[c1, c2].log().item()\n",
    "\n",
    "nll = -logp / len(bigrams)\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d90e06-37fe-4649-8e1b-00d56b588c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bioda.\n",
      ".amrarlionardonnth.\n",
      ".a.\n",
      ".dynzach.\n",
      ".ckarrll.\n",
      ".qur.\n",
      ".r.\n",
      ".ja.\n",
      ".deslishatelyawey.\n",
      ".y.\n"
     ]
    }
   ],
   "source": [
    "gen = torch.Generator()\n",
    "gen.manual_seed(2147483647)\n",
    "\n",
    "for _ in range(10):\n",
    "    sample = \".\"\n",
    "    while(True):\n",
    "        c1 = sample[-1]\n",
    "        i1 = ctoi[c1]\n",
    "        i2 = torch.multinomial(P[i1], 1, generator=gen).item()\n",
    "        sample += itoc[i2]\n",
    "\n",
    "        if i2 == 0:\n",
    "            break\n",
    "    \n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07a87b-f840-4e6f-a37d-ab2c6cb05f03",
   "metadata": {},
   "source": [
    "## Bigram Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e39298f-91f9-4e8d-9057-c1f524cbd888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_bigram_ds(names): \n",
    "    x = []\n",
    "    y = []\n",
    "    for s in names:\n",
    "        s = \".\" + s + \".\"\n",
    "        for c1, c2 in zip(s, s[1:]):\n",
    "            x.append(ctoi[c1])\n",
    "            y.append(ctoi[c2])\n",
    "    \n",
    "    x = F.one_hot(torch.tensor(x), num_classes=27).float()\n",
    "    y = torch.tensor(y)\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "x, y = create_bigram_ds(names)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40bea54f-5a58-404d-bbe6-377807fa6b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25627, 3203, 3203)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, dev, test = torch.utils.data.random_split(names, [0.8, 0.1, 0.1])\n",
    "len(train), len(dev), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825e9c3c-7609-4d39-a1bb-152f046bb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_bigram_ds(train)\n",
    "dev_ds = create_bigram_ds(dev)\n",
    "test_ds = create_bigram_ds(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e7b00a-5993-4a8e-8525-a7e28f566eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(W, dataset, decay=0):\n",
    "    with torch.no_grad():\n",
    "        X, ys = dataset\n",
    "        logits = X @ W\n",
    "        loss = F.cross_entropy(logits, ys)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f6f721e-4ef0-4af7-b9b3-3153d918d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits(W, train_ds, dev_ds, epoch, decay=0, verbose=True):\n",
    "    X, ys = train_ds\n",
    "    n = X.shape[0]\n",
    "    print_ev = epoch / 10\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        W.grad = None\n",
    "        logits = X @ W\n",
    "        \n",
    "        # counts = logits.exp()\n",
    "        # probs = counts / counts.sum(1, keepdims=True)\n",
    "        # loss = -probs[torch.arange(n), ys].log().mean() + decay*(W**2).mean()\n",
    "        \n",
    "        loss = F.cross_entropy(logits, ys) + decay*(W**2).mean()\n",
    "        loss.backward()\n",
    "\n",
    "        if i % print_ev == 0 and verbose:\n",
    "            dev_loss = cal_loss(W, dev_ds)\n",
    "            print(f\"train: {loss.item():.4f}  dev: {dev_loss:.4f}\")\n",
    "\n",
    "        W.data -= 10 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b97078a3-b69f-43a2-b636-ea41fa4a955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3.7315  dev: 3.7342\n",
      "train: 3.1569  dev: 3.1622\n",
      "train: 2.9238  dev: 2.9295\n",
      "train: 2.8028  dev: 2.8084\n",
      "train: 2.7294  dev: 2.7350\n",
      "train: 2.6802  dev: 2.6859\n",
      "train: 2.6449  dev: 2.6507\n",
      "train: 2.6184  dev: 2.6244\n",
      "train: 2.5978  dev: 2.6040\n",
      "train: 2.5815  dev: 2.5879\n",
      "----\n",
      "test: 2.568952798843384\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn(27, 27, requires_grad=True, generator=g)\n",
    "fits(W, train_ds, dev_ds, 100)\n",
    "print(\"----\")\n",
    "print(f\"test: {cal_loss(W, test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e83e78d1-5249-45ef-bfc9-263095f95316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3.7798  dev: 3.7342\n",
      "train: 3.1930  dev: 3.1573\n",
      "train: 2.9581  dev: 2.9247\n",
      "train: 2.8376  dev: 2.8044\n",
      "train: 2.7654  dev: 2.7318\n",
      "train: 2.7177  dev: 2.6836\n",
      "train: 2.6839  dev: 2.6493\n",
      "train: 2.6590  dev: 2.6238\n",
      "train: 2.6400  dev: 2.6042\n",
      "train: 2.6252  dev: 2.5888\n",
      "----\n",
      "test: 2.5708320140838623\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn(27, 27, requires_grad=True, generator=g)\n",
    "fits(W, train_ds, dev_ds, 100, 0.05)\n",
    "print(\"----\")\n",
    "print(f\"test: {cal_loss(W, test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e35bfef4-0755-481f-af9d-7f528c87b397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bioda.\n",
      ".amrarliqusedqwoth.\n",
      ".a.\n",
      ".dynzach.\n",
      ".cnarrlqdqqull.\n",
      ".ja.\n",
      ".deslishatelyawmo.\n",
      ".y.\n",
      ".dyne.\n",
      ".rol.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "def sample_bi(W):\n",
    "    res = \".\"\n",
    "    with torch.no_grad():\n",
    "        while(True):\n",
    "            c = res[-1]\n",
    "            x = torch.tensor(ctoi[c])\n",
    "            x = F.one_hot(x, num_classes=27).reshape(1, 27).float()\n",
    "\n",
    "            logits = x @ W\n",
    "            counts = logits.exp()\n",
    "            probs = counts / counts.sum(dim=1, keepdims=True)\n",
    "            ix = torch.multinomial(probs, 1, generator=g).item()\n",
    "            c2 = itoc[ix]\n",
    "\n",
    "            res += c2\n",
    "            if c2 == \".\":\n",
    "                break;\n",
    "\n",
    "        return res\n",
    "\n",
    "for _ in range(10):\n",
    "    print(sample_bi(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824847b-faf8-43f4-b240-56c356d0064e",
   "metadata": {},
   "source": [
    "# Trigram Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e54dd49-ea21-408a-91b9-7f504b6fb1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([208195, 54])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tri_ds(names): \n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for s in names:\n",
    "        s = \"..\" + s + \"..\"\n",
    "        for c1, c2, c3 in zip(s, s[1:], s[2:]):\n",
    "            x1.append(ctoi[c1])\n",
    "            x2.append(ctoi[c2])             \n",
    "            y.append(ctoi[c3])            \n",
    "                                          \n",
    "    x1 = F.one_hot(torch.tensor(x1), num_classes=27).float()\n",
    "    x2 = F.one_hot(torch.tensor(x2), num_classes=27).float()\n",
    "    x = torch.cat([x1, x2], dim=1) # (num_data, 2 * char_num)\n",
    "    y = torch.tensor(y)\n",
    "    return x, y\n",
    "    \n",
    "x, y = create_tri_ds(train)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d086db32-0ace-4cd3-a8bc-9889c273ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tds = create_tri_ds(train)\n",
    "dev_tds = create_tri_ds(dev)\n",
    "test_tds = create_tri_ds(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e03eaecf-32d8-491e-89b7-eb0e59f77bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay: 0\n",
      "----\n",
      "train: 4.1078  dev: 4.1029\n",
      "train: 2.8315  dev: 2.8253\n",
      "train: 2.5597  dev: 2.5544\n",
      "train: 2.4277  dev: 2.4244\n",
      "train: 2.3492  dev: 2.3479\n",
      "train: 2.2982  dev: 2.2982\n",
      "train: 2.2623  dev: 2.2633\n",
      "train: 2.2356  dev: 2.2372\n",
      "train: 2.2147  dev: 2.2169\n",
      "train: 2.1980  dev: 2.2005\n",
      "----\n",
      "test: 2.187288284301758\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "print(\"decay: 0\")\n",
    "print(\"----\")\n",
    "W = torch.randn(2 * 27, 27, requires_grad=True, generator=g)\n",
    "fits(W, train_tds, dev_tds, 100)\n",
    "print(\"----\")\n",
    "print(f\"test: {cal_loss(W, test_tds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01cb7035-6d86-4083-a7a3-04a15f89d134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay: 0.01\n",
      "----\n",
      "train: 4.2048  dev: 4.1029\n",
      "train: 2.9078  dev: 2.8171\n",
      "train: 2.6292  dev: 2.5449\n",
      "train: 2.4938  dev: 2.4150\n",
      "train: 2.4135  dev: 2.3390\n",
      "train: 2.3613  dev: 2.2899\n",
      "train: 2.3246  dev: 2.2556\n",
      "train: 2.2972  dev: 2.2301\n",
      "train: 2.2759  dev: 2.2103\n",
      "train: 2.2589  dev: 2.1946\n",
      "----\n",
      "test: 2.1817398071289062\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "print(\"decay: 0.01\")\n",
    "print(\"----\")\n",
    "W = torch.randn(2 * 27, 27, requires_grad=True, generator=g)\n",
    "fits(W, train_tds, dev_tds, 100, 0.1)\n",
    "print(\"----\")\n",
    "print(f\"test: {cal_loss(W, test_tds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e614446d-e823-4962-89ab-9c64388bd892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_expr(decay, epoch):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    W = torch.randn(2 * 27, 27, requires_grad=True, generator=g)\n",
    "    fits(W, train_tds, dev_tds, epoch, decay, verbose=False)\n",
    "    loss = cal_loss(W, test_tds)\n",
    "    print(f\"decay: {decay:.4f}  test: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "772b551d-e276-4096-8731-465df8482004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay: 0.0000  test: 2.1224\n",
      "decay: 0.0100  test: 2.1221\n",
      "decay: 0.0500  test: 2.1215\n",
      "decay: 0.1000  test: 2.1224\n"
     ]
    }
   ],
   "source": [
    "epoch = 200\n",
    "param_expr(0, epoch)\n",
    "param_expr(0.01, epoch)\n",
    "param_expr(0.05, epoch)\n",
    "param_expr(0.1, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d936a6a5-ac9d-4677-a8bc-7aaf83ea0067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay: 0.0000  test: 2.0721\n",
      "decay: 0.0100  test: 2.0725\n",
      "decay: 0.0500  test: 2.0773\n",
      "decay: 0.1000  test: 2.0861\n"
     ]
    }
   ],
   "source": [
    "epoch = 800\n",
    "param_expr(0, epoch)\n",
    "param_expr(0.01, epoch)\n",
    "param_expr(0.05, epoch)\n",
    "param_expr(0.1, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae483c40-5f25-48a3-9e6f-fd2ef876fb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..dyne.\n",
      "..rol.\n",
      "..diseix.\n",
      "..riqatsep.\n",
      "..jaxdlicqfuronn.\n",
      "..eefjshtrayuahuwvtalil.\n",
      "..kjxol.\n",
      "..ariya.\n",
      "..seyh.\n",
      "..yah.\n"
     ]
    }
   ],
   "source": [
    "def sample_tri(W):\n",
    "    # rdn_ix = torch.randint(1, 26, (1, )).item()\n",
    "    sample = \"..\"\n",
    "    while(True):\n",
    "        c1 = sample[-2]\n",
    "        c2 = sample[-1]\n",
    "        x1 = F.one_hot(torch.tensor([ctoi[c1]]), num_classes=27).float()\n",
    "        x2 = F.one_hot(torch.tensor([ctoi[c2]]), num_classes=27).float()\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        logits = x @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(dim=1, keepdims=True)\n",
    "        ix = torch.multinomial(probs, 1, generator=gen).item()\n",
    "        c3 = itoc[ix]\n",
    "\n",
    "        sample += c3\n",
    "        if c3 == \".\":\n",
    "            break;\n",
    "            \n",
    "    return sample\n",
    "\n",
    "for _ in range(10):\n",
    "    print(sample_tri(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa0a6d-50b3-416d-aed2-78db042c9326",
   "metadata": {},
   "source": [
    "# Exercise 5: Why use `F.cross_entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "862c73dc-c486-400c-a6c2-4179bfa4535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "n = 100\n",
    "feature_size = 1000\n",
    "\n",
    "W = torch.randn(feature_size, feature_size, requires_grad=False, generator=g)\n",
    "X = torch.randn(n, feature_size, requires_grad=True, generator=g)\n",
    "y = torch.randint(0, feature_size-1, (n,), generator=g)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a8734-0b8c-4973-8647-a7f754d56397",
   "metadata": {},
   "source": [
    "Manual calculation\n",
    "\n",
    "We can see that when logits is large (i.e. 100), we can easily each max value range when taking the exponent (`e^100`). Also observe that larger feature size would result in have larger logits value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "22f94844-d08d-4ea8-a99d-fe8f2019cde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits max: 137.92921447753906\n",
      "counts max: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = X@W\n",
    "print(f\"logits max: {logits.max().item()}\", )\n",
    "\n",
    "counts = logits.exp()\n",
    "print(f\"counts max: {counts.max().item()}\", )\n",
    "\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(y.shape[0]), y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9830ff-4c86-4936-b502-ff59d34092cc",
   "metadata": {},
   "source": [
    "Using `F.cross_entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bcd4b11c-f6a0-4a63-b2f7-7ce4148dc24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.7999, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, W, y = init_data()\n",
    "\n",
    "logits = X@W\n",
    "loss = F.cross_entropy(logits, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e418075-5a46-445a-aeaf-62bfa20e5ca7",
   "metadata": {},
   "source": [
    "# Exercise Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e64e3-61e3-41e1-ae57-02cde8d53c41",
   "metadata": {},
   "source": [
    "1. Train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?\n",
    "\n",
    "    > Trigram model seem to yield better loss\n",
    "\n",
    "2. Split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?\n",
    "    \n",
    "    \n",
    "3. use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?\n",
    "    \n",
    "    \n",
    "    > When training with 800 epoch, I yield an unexpected test loss pattern. \n",
    "    > ```\n",
    "        decay: 0.0000  test: 2.0665\n",
    "        decay: 0.0100  test: 2.0674\n",
    "        decay: 0.0500  test: 2.0733\n",
    "        decay: 0.1000  test: 2.0831\n",
    "    > ```  \n",
    "    > I expected regularization should help improve test loss, but from the experiments, no regularization seems to yield best test loss\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "4. We saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?\n",
    "\n",
    "1. Look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
