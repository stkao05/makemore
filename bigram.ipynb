{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1f08f0-08f6-4d09-a495-9f6104dfdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plot\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466d2563-6357-4f8d-ae55-f45fbba4f704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['emma', 'olivia', 'ava', 'isabella', 'sophia'], 32033)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"names.txt\", \"r\") as f:\n",
    "    names = [_.strip() for _ in f.readlines()]\n",
    "\n",
    "names[0:5], len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d24d37e-fe18-4bc5-8429-509f8967b26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 't',\n",
       " 'w',\n",
       " 'y',\n",
       " 'h',\n",
       " 'b',\n",
       " 'q',\n",
       " 'z',\n",
       " 'g',\n",
       " 'l',\n",
       " 'r',\n",
       " 'c',\n",
       " 'm',\n",
       " 'n',\n",
       " 'u',\n",
       " 'e',\n",
       " 'i',\n",
       " 'v',\n",
       " 'p',\n",
       " 'j',\n",
       " 'o',\n",
       " 'd',\n",
       " 'x',\n",
       " 'a',\n",
       " 'k',\n",
       " 's',\n",
       " 'f']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(set(\"\".join(names)))\n",
    "chars.insert(0, \".\")\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ecb7279-15ec-4185-84ad-f44d0d231019",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctoi = { c:i for i, c in enumerate(chars)}\n",
    "itoc = { i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a844b3bf-c723-4b44-b011-b54e76371c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16bcae7d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int) # N is count vector\n",
    "\n",
    "for x in names:\n",
    "    x = \".\" + x + \".\"\n",
    "    for c1, c2 in zip(x, x[1:]):\n",
    "        c1i = ctoi[c1]\n",
    "        c2i = ctoi[c2]\n",
    "        N[c1i, c2i] += 1\n",
    "        \n",
    "plot.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "841f85a6-1f7d-439a-bd4e-47324d3e44ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = N / N.sum(dim=1, keepdims=True)\n",
    "P[5,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b672955-3cbb-4160-a900-298ec96ed0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = []\n",
    "for x in names:\n",
    "    x = \".\" + x + \".\"\n",
    "    for c1, c2 in zip(x, x[1:]):\n",
    "        bigrams.append((c1, c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "243087a3-4e53-4a32-91eb-e4a5d47c8b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.454014497322693"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp = 0;\n",
    "for c1, c2 in bigrams:\n",
    "    c1 = ctoi[c1]\n",
    "    c2 = ctoi[c2]\n",
    "    logp += P[c1, c2].log().item()\n",
    "\n",
    "nll = -logp / len(bigrams)\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47d90e06-37fe-4649-8e1b-00d56b588c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".h.\n",
      ".kwn.\n",
      ".menicariley.\n",
      ".coshanin.\n",
      ".lyronalan.\n",
      ".caha.\n",
      ".ce.\n",
      ".da.\n",
      ".jan.\n",
      ".siderariyn.\n"
     ]
    }
   ],
   "source": [
    "gen = torch.Generator()\n",
    "gen.manual_seed(2147483647)\n",
    "\n",
    "for _ in range(10):\n",
    "    sample = \".\"\n",
    "    while(True):\n",
    "        c1 = sample[-1]\n",
    "        i1 = ctoi[c1]\n",
    "        i2 = torch.multinomial(P[i1], 1, generator=gen).item()\n",
    "        sample += itoc[i2]\n",
    "\n",
    "        if i2 == 0:\n",
    "            break\n",
    "    \n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07a87b-f840-4e6f-a37d-ab2c6cb05f03",
   "metadata": {},
   "source": [
    "## Bigram Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e39298f-91f9-4e8d-9057-c1f524cbd888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_bigram_ds(names): \n",
    "    x = []\n",
    "    y = []\n",
    "    for s in names:\n",
    "        s = \".\" + s + \".\"\n",
    "        for c1, c2 in zip(s, s[1:]):\n",
    "            x.append(ctoi[c1])\n",
    "            y.append(ctoi[c2])\n",
    "    \n",
    "    x = F.one_hot(torch.tensor(x), num_classes=27).float()\n",
    "    y = torch.tensor(y)\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "x, y = create_bigram_ds(names)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40bea54f-5a58-404d-bbe6-377807fa6b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25627, 3203, 3203)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, dev, test = torch.utils.data.random_split(names, [0.8, 0.1, 0.1])\n",
    "len(train), len(dev), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825e9c3c-7609-4d39-a1bb-152f046bb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_bigram_ds(train)\n",
    "dev_ds = create_bigram_ds(dev)\n",
    "test_ds = create_bigram_ds(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "50e7b00a-5993-4a8e-8525-a7e28f566eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(W, dataset, decay=0):\n",
    "    with torch.no_grad():\n",
    "        X, ys = dataset\n",
    "        logits = X @ W\n",
    "        loss = F.cross_entropy(logits, ys)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7f6f721e-4ef0-4af7-b9b3-3153d918d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits(W, train_ds, dev_ds, epoch, decay=0, verbose=True):\n",
    "    X, ys = train_ds\n",
    "    n = X.shape[0]\n",
    "    print_ev = epoch / 10\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        W.grad = None\n",
    "        logits = X @ W\n",
    "        \n",
    "        # counts = logits.exp()\n",
    "        # probs = counts / counts.sum(1, keepdims=True)\n",
    "        # loss = -probs[torch.arange(n), ys].log().mean() + decay*(W**2).mean()\n",
    "        \n",
    "        loss = F.cross_entropy(logits, ys) + decay*(W**2).mean()\n",
    "        loss.backward()\n",
    "\n",
    "        if i % print_ev == 0 and verbose:\n",
    "            dev_loss = cal_loss(W, dev_ds)\n",
    "            print(f\"train: {loss.item():.4f}  dev: {dev_loss:.4f}\")\n",
    "\n",
    "        W.data -= 10 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b97078a3-b69f-43a2-b636-ea41fa4a955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3.6411  dev: 3.6535\n",
      "train: 3.1051  dev: 3.1184\n",
      "train: 2.8729  dev: 2.8870\n",
      "train: 2.7548  dev: 2.7695\n",
      "train: 2.6884  dev: 2.7034\n",
      "train: 2.6469  dev: 2.6618\n",
      "train: 2.6181  dev: 2.6329\n",
      "train: 2.5968  dev: 2.6114\n",
      "train: 2.5803  dev: 2.5945\n",
      "train: 2.5670  dev: 2.5810\n",
      "----\n",
      "test: 2.562330961227417\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn(27, 27, requires_grad=True, generator=g)\n",
    "fits(W, train_ds, dev_ds, 100)\n",
    "print(\"----\")\n",
    "print(f\"test: {cal_loss(W, test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e83e78d1-5249-45ef-bfc9-263095f95316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3.6894  dev: 3.6535\n",
      "train: 3.1430  dev: 3.1142\n",
      "train: 2.9103  dev: 2.8835\n",
      "train: 2.7939  dev: 2.7671\n",
      "train: 2.7293  dev: 2.7018\n",
      "train: 2.6892  dev: 2.6608\n",
      "train: 2.6619  dev: 2.6324\n",
      "train: 2.6418  dev: 2.6114\n",
      "train: 2.6265  dev: 2.5950\n",
      "train: 2.6144  dev: 2.5820\n",
      "----\n",
      "test: 2.564791679382324\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn(27, 27, requires_grad=True, generator=g)\n",
    "fits(W, train_ds, dev_ds, 100, 0.05)\n",
    "print(\"----\")\n",
    "print(f\"test: {cal_loss(W, test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e35bfef4-0755-481f-af9d-7f528c87b397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".h.\n",
      ".kfn.\n",
      ".menicdecanifcosganin.\n",
      ".lyronalan.\n",
      ".cahcfce.\n",
      ".da.\n",
      ".jankoiderariynzeoni.\n",
      ".leflevackeriaionh.\n",
      ".anconnan.\n",
      ".johzd.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "def sample_bi(W):\n",
    "    res = \".\"\n",
    "    with torch.no_grad():\n",
    "        while(True):\n",
    "            c = res[-1]\n",
    "            x = torch.tensor(ctoi[c])\n",
    "            x = F.one_hot(x, num_classes=27).reshape(1, 27).float()\n",
    "\n",
    "            logits = x @ W\n",
    "            counts = logits.exp()\n",
    "            probs = counts / counts.sum(dim=1, keepdims=True)\n",
    "            ix = torch.multinomial(probs, 1, generator=g).item()\n",
    "            c2 = itoc[ix]\n",
    "\n",
    "            res += c2\n",
    "            if c2 == \".\":\n",
    "                break;\n",
    "\n",
    "        return res\n",
    "\n",
    "for _ in range(10):\n",
    "    print(sample_bi(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824847b-faf8-43f4-b240-56c356d0064e",
   "metadata": {},
   "source": [
    "# Trigram Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e54dd49-ea21-408a-91b9-7f504b6fb1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([208150, 54])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tri_ds(names): \n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for s in names:\n",
    "        s = \"..\" + s + \"..\"\n",
    "        for c1, c2, c3 in zip(s, s[1:], s[2:]):\n",
    "            x1.append(ctoi[c1])\n",
    "            x2.append(ctoi[c2])             \n",
    "            y.append(ctoi[c3])            \n",
    "                                          \n",
    "    x1 = F.one_hot(torch.tensor(x1), num_classes=27).float()\n",
    "    x2 = F.one_hot(torch.tensor(x2), num_classes=27).float()\n",
    "    x = torch.cat([x1, x2], dim=1) # (num_data, 2 * char_num)\n",
    "    y = torch.tensor(y)\n",
    "    return x, y\n",
    "    \n",
    "x, y = create_tri_ds(train)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d086db32-0ace-4cd3-a8bc-9889c273ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tds = create_tri_ds(train)\n",
    "dev_tds = create_tri_ds(dev)\n",
    "test_tds = create_tri_ds(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e03eaecf-32d8-491e-89b7-eb0e59f77bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay: 0\n",
      "----\n",
      "train: 4.1165  dev: 4.1235\n",
      "train: 2.8635  dev: 2.8786\n",
      "train: 2.5490  dev: 2.5650\n",
      "train: 2.4113  dev: 2.4271\n",
      "train: 2.3368  dev: 2.3523\n",
      "train: 2.2895  dev: 2.3048\n",
      "train: 2.2561  dev: 2.2713\n",
      "train: 2.2311  dev: 2.2461\n",
      "train: 2.2116  dev: 2.2264\n",
      "train: 2.1960  dev: 2.2106\n",
      "----\n",
      "test: 2.1861460208892822\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "print(\"decay: 0\")\n",
    "print(\"----\")\n",
    "W = torch.randn(2 * 27, 27, requires_grad=True, generator=g)\n",
    "fits(W, train_tds, dev_tds, 100)\n",
    "print(\"----\")\n",
    "print(f\"test: {cal_loss(W, test_tds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "01cb7035-6d86-4083-a7a3-04a15f89d134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay: 0.01\n",
      "----\n",
      "train: 4.2135  dev: 4.1235\n",
      "train: 2.9386  dev: 2.8696\n",
      "train: 2.6187  dev: 2.5555\n",
      "train: 2.4787  dev: 2.4181\n",
      "train: 2.4025  dev: 2.3436\n",
      "train: 2.3539  dev: 2.2964\n",
      "train: 2.3195  dev: 2.2631\n",
      "train: 2.2937  dev: 2.2383\n",
      "train: 2.2736  dev: 2.2190\n",
      "train: 2.2574  dev: 2.2037\n",
      "----\n",
      "test: 2.1805543899536133\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "print(\"decay: 0.01\")\n",
    "print(\"----\")\n",
    "W = torch.randn(2 * 27, 27, requires_grad=True, generator=g)\n",
    "fits(W, train_tds, dev_tds, 100, 0.1)\n",
    "print(\"----\")\n",
    "print(f\"test: {cal_loss(W, test_tds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e614446d-e823-4962-89ab-9c64388bd892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_expr(decay, epoch):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    W = torch.randn(2 * 27, 27, requires_grad=True, generator=g)\n",
    "    fits(W, train_tds, dev_tds, epoch, decay, verbose=False)\n",
    "    loss = cal_loss(W, test_tds)\n",
    "    print(f\"decay: {decay:.4f}  test: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "772b551d-e276-4096-8731-465df8482004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay: 0.0000  test: 2.1227\n",
      "decay: 0.0100  test: 2.1222\n",
      "decay: 0.0500  test: 2.1213\n",
      "decay: 0.1000  test: 2.1220\n"
     ]
    }
   ],
   "source": [
    "epoch = 200\n",
    "param_expr(0, epoch)\n",
    "param_expr(0.01, epoch)\n",
    "param_expr(0.05, epoch)\n",
    "param_expr(0.1, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d936a6a5-ac9d-4677-a8bc-7aaf83ea0067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay: 0.0000  test: 2.0665\n",
      "decay: 0.0100  test: 2.0674\n",
      "decay: 0.0500  test: 2.0733\n",
      "decay: 0.1000  test: 2.0831\n"
     ]
    }
   ],
   "source": [
    "epoch = 800\n",
    "param_expr(0, epoch)\n",
    "param_expr(0.01, epoch)\n",
    "param_expr(0.05, epoch)\n",
    "param_expr(0.1, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ae483c40-5f25-48a3-9e6f-fd2ef876fb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..ariyah.\n",
      "..draniearasamx.\n",
      "..jumadxjlf.\n",
      "..tea.\n",
      "..wadlin.\n",
      "..fbzesen.\n",
      "..sae.\n",
      "..cia.\n",
      "..na.\n",
      "..eon.\n"
     ]
    }
   ],
   "source": [
    "def sample_tri(W):\n",
    "    # rdn_ix = torch.randint(1, 26, (1, )).item()\n",
    "    sample = \"..\"\n",
    "    while(True):\n",
    "        c1 = sample[-2]\n",
    "        c2 = sample[-1]\n",
    "        x1 = F.one_hot(torch.tensor([ctoi[c1]]), num_classes=27).float()\n",
    "        x2 = F.one_hot(torch.tensor([ctoi[c2]]), num_classes=27).float()\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "\n",
    "        logits = x @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(dim=1, keepdims=True)\n",
    "        ix = torch.multinomial(probs, 1, generator=gen).item()\n",
    "        c3 = itoc[ix]\n",
    "\n",
    "        sample += c3\n",
    "        if c3 == \".\":\n",
    "            break;\n",
    "            \n",
    "    return sample\n",
    "\n",
    "for _ in range(10):\n",
    "    print(sample_tri(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa0a6d-50b3-416d-aed2-78db042c9326",
   "metadata": {},
   "source": [
    "# Cross Entropy vs Manual Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "862c73dc-c486-400c-a6c2-4179bfa4535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_data():\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    n = 100\n",
    "    feature_size = 100\n",
    "\n",
    "    W = torch.randn(feature_size, feature_size, requires_grad=True, generator=g)\n",
    "    X = torch.randn(n, feature_size, requires_grad=True, generator=g)\n",
    "    y = torch.randint(0, feature_size-1, (n,), generator=g)    \n",
    "    \n",
    "    return X, W, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a8734-0b8c-4973-8647-a7f754d56397",
   "metadata": {},
   "source": [
    "Manual calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "22f94844-d08d-4ea8-a99d-fe8f2019cde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 2 µs, total: 7 µs\n",
      "Wall time: 12.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(23.7999, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "X, W, y = init_data()\n",
    "\n",
    "logits = X@W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(y.shape[0]), y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9830ff-4c86-4936-b502-ff59d34092cc",
   "metadata": {},
   "source": [
    "Using `F.cross_entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "bcd4b11c-f6a0-4a63-b2f7-7ce4148dc24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 2 µs, total: 7 µs\n",
      "Wall time: 15 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(23.7999, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "X, W, y = init_data()\n",
    "\n",
    "logits = X@W\n",
    "loss = F.cross_entropy(logits, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e418075-5a46-445a-aeaf-62bfa20e5ca7",
   "metadata": {},
   "source": [
    "# Exercise Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e64e3-61e3-41e1-ae57-02cde8d53c41",
   "metadata": {},
   "source": [
    "1. Train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?\n",
    "\n",
    "    > Trigram model seem to yield better loss\n",
    "\n",
    "2. Split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?\n",
    "    \n",
    "    \n",
    "3. use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?\n",
    "    \n",
    "    \n",
    "    > When training with 800 epoch, I yield an unexpected test loss pattern. \n",
    "    > ```\n",
    "        decay: 0.0000  test: 2.0665\n",
    "        decay: 0.0100  test: 2.0674\n",
    "        decay: 0.0500  test: 2.0733\n",
    "        decay: 0.1000  test: 2.0831\n",
    "    > ```  \n",
    "    > I expected regularization should help improve test loss, but from the experiments, no regularization seems to yield best test loss\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "4. We saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?\n",
    "\n",
    "1. Look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
